<div class="accordion mb-3" id="accordion-discovery-explanation">
    <div class="accordion-item">
        <h2 class="accordion-header" id="headingOne">
            <button class="accordion-button collapsed explanation-header" type="button" data-bs-toggle="collapse"
                data-bs-target="#collapseOne" aria-expanded="false" aria-controls="collapseOne"
                data-bs-parent="#accordion-discovery-explanation">
                Show / hide materials discovery explanation
            </button>
        </h2>
        <div id="collapseOne" class="accordion-collapse collapse" aria-labelledby="headingOne">
            <div class="accordion-body explanation-body" role="tooltip">
                In this form you can run machine learning experiments to discover interesting material
                combinations.
                This is measured by their utility, which is computed using
                predicted target properties, as well as prior knowledge about properties derived from the
                input.

                First, select the properties you want to work with:
                <ol>
                    <li>Select a data set to work on from the table above using the blue checkmark buttons.</li>
                    <li>Select Materials Data columns (features) that you want to use in your experiment in the left
                        selection box.
                    </li>
                    <li>Select the target properties you want to predict in the center selection box.</li>
                    <li>Select derived properties that you want to use to maximize utility.</li>
                </ol>

                <p>
                    You can use Ctrl+Click or Shift+Click to select multiple properties in each selection box.
                </p>

                Next, select how you want to use these derived and target properties:
                <ul>
                    <li>For each property choose if you want to maximize or minimize it.</li>
                    <li>You may adjust the weight of each property in the utility calculation.</li>
                    <li>You may specify a threshold for each property.
                        <ul>
                            <li>For derived properties, rows outside of the threshold will be dropped.</li>
                            <li>
                                For target properties, values will be clamped to the threshold during the
                                utility
                                calculation. The values shown in the results table below will remain unchanged.
                            </li>
                        </ul>
                    </li>
                </ul>

                Finally, you may choose a machine learning model, as well as a curiosity value.
                <ul>
                    <li>
                        There are currently {% if tuned_models_explanation_active %} 6 {% else %} 4 {% endif %}
                        machine learning models available: Gaussian Process Regression and Random Forest Regression,
                        plus their variations that run Principal Component Analysis before
                        {% if tuned_models_explanation_active %} plus their tuned versions optimized with feature
                        selection and grid search{% endif %}.
                        If you are not sure which one to use, choose the basic GPR as it generally produces better
                        results.
                    </li>
                    {% if tuned_models_explanation_active %}
                    <li>
                        In case you select the tuned versions of the algorithms, please be patient as the algorithms
                        might run for a couple of seconds. Note that the tuned versions require the targets to have at
                        least 4 labels. The tuned versions only support one target column for the time being.
                    </li>
                    {% endif %}
                    <li>
                        The curiosity value affects the calculation of the utility function. The uncertainty of
                        predicted values is added to the utility, weighted by the curiosity. This way, points with
                        large uncertainties are preferred. They provide more information gain if measured than points
                        with lower uncertainty.
                        <ul>
                            <li>
                                If the curiosity is greater than 1 this effect is amplified. Predictions with
                                large uncertainty are favored disproportionally.
                            </li>
                            <li>
                                If the curiosity is between 0 and 1 this effect is lessened. Predictions with large
                                uncertainty are still favored, but the uncertainty is less important to the utility
                                overall.
                            </li>
                            <li>
                                If the curiosity is negative the uncertainty is subtracted instead, providing a
                                penalty to the utility. This favors predictions with low uncertainty.
                            </li>
                        </ul>
                        Use larger curiosity values if you want to explore the parameter space by covering a wide area,
                        as points at a distance will be less certain in their prediction than nearby points.
                        Use smaller or negative curiosity if you think you have identified a desirable area of the
                        parameter space and want to refine ("exploit") your results by finding a nearby optimum.
                    </li>
                </ul>
            </div>
        </div>
    </div>
</div>

<form action="" method="post" novalidate>
    <div class="row g-3 mb-3 align-items-end">
        <div class="col-12 col-md-4">
            {{ discovery_form.materials_data_input.label(class_="control-label") }}
            {{ discovery_form.materials_data_input(class_="form-control form-select multiple-select-lg") }}
        </div>
        <div class="col-12 col-md-4">
            {{ discovery_form.target_properties.label(class_="control-label") }}
            {{ discovery_form.target_properties(class_="form-control form-select multiple-select-lg") }}
        </div>
        <div class="col-12 col-md-4">
            {{ discovery_form.a_priori_information.label(class_="control-label") }}
            {{ discovery_form.a_priori_information(class_="form-control form-select multiple-select-lg") }}
        </div>
    </div>
    <div id="target-configuration-form-placeholder"></div>
    <div id="a-priori-information-configuration-form-placeholder"></div>
    <div class="row g-3 mb-3">
        <div class="col-12 col-md-6">
            {{ discovery_form.model.label(class_="control-label") }}
            {{ discovery_form.model(class_="form-control form-select") }}
        </div>
        <div class="col-12 col-md-6">
            <div class="col-12">
                {{ discovery_form.curiosity.label(class_="control-label") }}
                {{ discovery_form.curiosity(class_="form-range", min=-1, max=5, oninput="updateCuriosityValue(value)")
                }}
            </div>
            <div class="row">
                <div class="col-4">Exploit</div>
                <div class="col-4" style="text-align: center">
                    <output for="curiosity" id="selected-range">{{ discovery_form.curiosity.data }}</output>
                </div>
                <div class="col-4" style="text-align: right">Explore</div>
            </div>
        </div>
    </div>
    <button id="run-experiment-button" class="btn btn-success col-12 mb-3" type="button" data-bs-toggle="tooltip"
        data_bs_placement="bottom" title="Select at least a target and whether it should be maximized or minimized"
        disabled>
        Run experiment with given configuration
    </button>
</form>